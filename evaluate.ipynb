{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_min_max_norm(x, original):\n",
    "    return (x + 1) * (np.max(original) - np.min(original)) / 2 + np.min(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y, y_pred):\n",
    "    return torch.sqrt(torch.mean((y - y_pred)**2) + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y, label_scalers):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.process_time()\n",
    "    # get data of test data for each state\n",
    "    for file in test_x.keys():\n",
    "        inputs = torch.from_numpy(np.array(test_x[file]))\n",
    "        labels = torch.from_numpy(np.array(test_y[file]))\n",
    "\n",
    "        h = model.init_hidden(inputs.shape[0])\n",
    "\n",
    "        # predict outputs\n",
    "        with torch.no_grad():\n",
    "            out, h = model(inputs.to(device).float(), h)\n",
    "\n",
    "        outputs.append(\n",
    "            label_scalers[file]\n",
    "            .inverse_transform(out.cpu().detach().numpy())\n",
    "            .reshape(-1)\n",
    "        )\n",
    "\n",
    "        targets.append(\n",
    "            label_scalers[file].inverse_transform(labels.numpy()).reshape(-1)\n",
    "        )\n",
    "\n",
    "    # Merge all files\n",
    "    concatenated_outputs = np.concatenate(outputs)\n",
    "    concatenated_targets = np.concatenate(targets)\n",
    "\n",
    "    print(f\"Evaluation Time: {time.process_time()-start_time}\")\n",
    "    print(f\"sMAPE: {round(RMSE(concatenated_outputs, concatenated_targets), 3)}%\")\n",
    "\n",
    "    # list of of targets/outputs for each state\n",
    "    return outputs, targets, RMSE(concatenated_outputs, concatenated_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = list(test_x.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(gru_outputs[0][-100:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(\n",
    "    lstm_outputs[0][-100:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2\n",
    ")\n",
    "plt.plot(targets[0][-100:], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[0]} state\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(gru_outputs[1][-50:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[1][-50:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[1][-50:], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[1]} state\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(gru_outputs[2][:50], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[2][:50], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[2][:50], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[2]} state\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(gru_outputs[3][:100], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[3][:100], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[3][:100], color=\"b\", label=\"Actual\")\n",
    "plt.title(f\"Energy Consumption for {states_list[3]} state\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
