{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import os \n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from collections import defaultdict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make supervised learning dataset from csv files\n",
    "#TODO build dataloader\n",
    "solar_data = np.genfromtxt('data\\\\training_data\\\\train_solar.csv', delimiter=',', skip_header=1)\n",
    "wind_data = np.genfromtxt('data\\\\training_data\\\\train_wind.csv', delimiter=',',skip_header=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17544, 11), (17544, 11))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solar_data.shape, wind_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sliding_window(data, window_size, inputs_cols_indices, label_col_index):\n",
    "    \"\"\"\n",
    "    data: numpy array including data\n",
    "    window_size: size of window\n",
    "    inputs_cols_indices: col indices to include\n",
    "    \"\"\"\n",
    "\n",
    "    # (# instances created by movement, seq_len (timestamps), # features (input_len))\n",
    "    inputs = np.zeros((len(data) - window_size, window_size, len(inputs_cols_indices)))\n",
    "    labels = np.zeros(len(data) - window_size)\n",
    "\n",
    "    for i in range(window_size, len(data)):\n",
    "        inputs[i - window_size] = data[i - window_size : i, inputs_cols_indices]\n",
    "        labels[i - window_size] = data[i, label_col_index]\n",
    "    inputs = inputs.reshape(-1, window_size, len(inputs_cols_indices))\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    print(inputs.shape, labels.shape)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sliding_window_24h(data, window_size, inputs_cols_indices, label_col_index, forecast_horizon=24):\n",
    "    \"\"\"\n",
    "    data: numpy array including data\n",
    "    window_size: size of window\n",
    "    inputs_cols_indices: col indices to include\n",
    "    label_col_index: index of the label column in data\n",
    "    forecast_horizon: number of time steps ahead to predict\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the number of instances based on the available data minus the window size and forecast horizon\n",
    "    num_instances = len(data) - window_size - forecast_horizon + 1\n",
    "\n",
    "    # (# instances created by movement, seq_len (timestamps), # features (input_len))\n",
    "    inputs = np.zeros((num_instances, window_size, len(inputs_cols_indices)))\n",
    "    labels = np.zeros(num_instances)\n",
    "\n",
    "    for i in range(num_instances):\n",
    "        inputs[i] = data[i:i + window_size, inputs_cols_indices]\n",
    "        labels[i] = data[i + window_size + forecast_horizon - 1, label_col_index]  # Label is forecast_horizon steps ahead\n",
    "\n",
    "    print(inputs.shape, labels.shape)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17519, 25, 11) (17519, 1)\n",
      "(17519, 25, 11) (17519, 1)\n"
     ]
    }
   ],
   "source": [
    "solar_X, solar_y = move_sliding_window(solar_data, WINDOW_SIZE, range(11), 0)\n",
    "wind_X, wind_y = move_sliding_window(wind_data, WINDOW_SIZE, range(11), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.         -1.         -1.         -0.39492153  0.21077271\n",
      "   0.          1.          1.          1.          1.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.39191435  0.21077271\n",
      "   1.          1.          1.          1.          1.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.39321545  0.21077271\n",
      "   2.          1.          1.          1.          1.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.39499721  0.21077271\n",
      "   3.          1.          1.          1.          1.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.39659511  0.21077271\n",
      "   4.          1.          1.          1.          1.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.39866141  0.21077271\n",
      "   5.          1.          1.          1.          1.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.40071957  0.21077271\n",
      "   6.          1.          1.          1.          1.        ]\n",
      " [-1.         -0.99999988 -0.99999955 -1.         -0.40273931  0.21077271\n",
      "   7.          1.          1.          1.          1.        ]\n",
      " [-0.99853643 -0.99972145 -0.99931288 -0.99889496 -0.40407701  0.213805\n",
      "   8.          1.          1.          1.          1.        ]\n",
      " [-0.98929614 -0.99782193 -0.9954876  -0.9923473  -0.40284649  0.23641761\n",
      "   9.          1.          1.          1.          1.        ]\n",
      " [-0.96981727 -0.99303483 -0.98698748 -0.97767768 -0.39909725  0.28255127\n",
      "  10.          1.          1.          1.          1.        ]\n",
      " [-0.94386172 -0.98444738 -0.97311783 -0.95497492 -0.39420079  0.33970077\n",
      "  11.          1.          1.          1.          1.        ]\n",
      " [-0.91972428 -0.97255544 -0.95463834 -0.92594911 -0.38939845  0.3928102\n",
      "  12.          1.          1.          1.          1.        ]\n",
      " [-0.90233704 -0.9584131  -0.93295393 -0.89033537 -0.38637763  0.42927765\n",
      "  13.          1.          1.          1.          1.        ]\n",
      " [-0.89661751 -0.94385861 -0.91027532 -0.85133526 -0.38565071  0.44081332\n",
      "  14.          1.          1.          1.          1.        ]\n",
      " [-0.90230602 -0.93031973 -0.88873051 -0.81249776 -0.38785276  0.42824321\n",
      "  15.          1.          1.          1.          1.        ]\n",
      " [-0.91235789 -0.91851156 -0.86984705 -0.77819059 -0.39309527  0.40597748\n",
      "  16.          1.          1.          1.          1.        ]\n",
      " [-0.92138079 -0.90821363 -0.85337878 -0.74827128 -0.39905     0.38588082\n",
      "  17.          1.          1.          1.          1.        ]\n",
      " [-0.92929317 -0.89918317 -0.83893739 -0.7220344  -0.4059161   0.36825763\n",
      "  18.          1.          1.          1.          1.        ]\n",
      " [-0.93626531 -0.89122579 -0.82621209 -0.69891526 -0.41373908  0.35272862\n",
      "  19.          1.          1.          1.          1.        ]\n",
      " [-0.94243516 -0.88418409 -0.81495111 -0.67845648 -0.42138304  0.33898655\n",
      "  20.          1.          1.          1.          1.        ]\n",
      " [-0.94791563 -0.87792917 -0.80494834 -0.66028361 -0.42959775  0.32677992\n",
      "  21.          1.          1.          1.          1.        ]\n",
      " [-0.95280007 -0.87235452 -0.79603345 -0.64408717 -0.43792583  0.31590085\n",
      "  22.          1.          1.          1.          1.        ]\n",
      " [-0.95716628 -0.86737132 -0.78806439 -0.62960911 -0.44595844  0.30617601\n",
      "  23.          1.          1.          1.          1.        ]\n",
      " [-0.96107966 -0.87948857 -0.8074273  -0.66344887 -0.45576854  0.06130266\n",
      "   0.          2.          2.          1.          2.        ]] \n",
      " [-0.96459556]\n"
     ]
    }
   ],
   "source": [
    "print(solar_X[0], '\\n', solar_y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset\n",
    "class SolarDataset(Dataset):\n",
    "    def __init__(self, inputs, output):\n",
    "        self.inputs = inputs\n",
    "        self.output = output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.output[idx]\n",
    "\n",
    "solar_dataset = SolarDataset(solar_X, solar_y)\n",
    "wind_dataset = SolarDataset(wind_X, wind_y)\n",
    "dataloader_solar = DataLoader(solar_dataset, batch_size=32, shuffle=False, drop_last=True) \n",
    "dataloader_wind = DataLoader(wind_dataset, batch_size=32, shuffle=False, drop_last=True)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8735, 25, 11) (8735, 1)\n"
     ]
    }
   ],
   "source": [
    "solar_data_val = np.genfromtxt('data\\\\training_data\\\\val_solar.csv', delimiter=',', skip_header=1)\n",
    "solar_X_val, solar_y_val = move_sliding_window(solar_data_val, WINDOW_SIZE, range(11), 0)\n",
    "solar_dataset_val = SolarDataset(solar_X_val, solar_y_val)\n",
    "dataloader_solar_val = DataLoader(solar_dataset_val, batch_size=32, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8735, 25, 11) (8735, 1)\n"
     ]
    }
   ],
   "source": [
    "wind_data_val = np.genfromtxt('data\\\\training_data\\\\val_wind.csv', delimiter=',', skip_header=1)\n",
    "wind_X_val, wind_y_val = move_sliding_window(wind_data_val, WINDOW_SIZE, range(11), 0)\n",
    "wind_dataset_val = SolarDataset(wind_X_val, wind_y_val)\n",
    "dataloader_wind_val = DataLoader(wind_dataset_val, batch_size=32, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731.0\n"
     ]
    }
   ],
   "source": [
    "alpha = 2\n",
    "N_h = solar_data.shape[0] / (alpha * (11 + 1))\n",
    "print(N_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GRU_model import GRUNet\n",
    "\n",
    "INPUT_SIZE = solar_X.shape[2]\n",
    "HIDDEN_SIZE = 16\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_SIZE = solar_y.shape[1]\n",
    "DROP_PROB = .5\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 1\n"
     ]
    }
   ],
   "source": [
    "print(INPUT_SIZE, OUTPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUNet(\n",
       "  (gru): GRU(11, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GRUNet(input_dim=INPUT_SIZE, hidden_dim=HIDDEN_SIZE, output_dim=OUTPUT_SIZE, n_layers=NUM_LAYERS, drop_prob=DROP_PROB).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, grad_clip_param, apply_gradient_clipping=False):   \n",
    "    model.train()\n",
    "    losses_train = []\n",
    "    losses_val = [] \n",
    "    best_val_loss = np.inf\n",
    "    best_epoch = 0\n",
    "    eps = 1e-6\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_losses = []\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            \n",
    "            \n",
    "            input, target  = input.to(device), target.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            h = model.init_hidden(input.size(0)).to(device)\n",
    "            \n",
    "            output, hidden = model(input.float(), h)\n",
    "\n",
    "            loss = torch.sqrt(criterion(output, target.float()) + eps)\n",
    "            # gradient clipping\n",
    "            loss.backward()\n",
    "            if apply_gradient_clipping:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_param)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # validate\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(val_loader):\n",
    "                input, target  = input.to(device), target.to(device)\n",
    "                h = model.init_hidden(input.size(0)).to(device)\n",
    "                output, hidden = model(input.float(), h)\n",
    "                    \n",
    "                val_loss = criterion(output, target.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "        \"\"\"\n",
    "        #print epoch results\n",
    "        print(f'Epoch {epoch}, train loss: {np.mean(train_losses)}')\n",
    "\n",
    "                \n",
    "        losses_train.append(np.mean(train_losses))\n",
    "        #losses_val.append(np.mean(val_losses))\n",
    "\n",
    "    return model, losses_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain Model on entire dataset using the before found hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Béla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#Best parameters: {'batch_size': 16, 'iterator_train__shuffle': False, 'max_epochs': 80, 'module__drop_prob': 0.5, 'module__hidden_dim': 16, 'module__n_layers': 1, 'optimizer__lr': 0.001, 'optimizer__weight_decay': 0.0001}\n",
    "\n",
    "HIDDEN_SIZE = 16\n",
    "NUM_LAYERS = 1\n",
    "lr = 0.001\n",
    "weight_decay = 0.001\n",
    "N_EPOCHS = 100\n",
    "DROP_PROB = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "grad_clip_param = 2\n",
    "\n",
    "\n",
    "\n",
    "model = GRUNet(input_dim=INPUT_SIZE, hidden_dim=HIDDEN_SIZE, output_dim=OUTPUT_SIZE, n_layers=NUM_LAYERS, drop_prob=DROP_PROB).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26279, 25, 11) (26279, 1)\n"
     ]
    }
   ],
   "source": [
    "# retrain on entire dataset \n",
    "wind_total = np.concatenate((wind_data, wind_data_val), axis=0)\n",
    "wind_total_X, wind_total_y = move_sliding_window(wind_total, WINDOW_SIZE, range(11), 0)\n",
    "wind_total_dataset = SolarDataset(wind_total_X, wind_total_y)\n",
    "dataloader_wind_total = DataLoader(wind_total_dataset, batch_size=32, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.3566136930986386\n",
      "Epoch 1, train loss: 0.34242739341018696\n",
      "Epoch 2, train loss: 0.3292815538120981\n",
      "Epoch 3, train loss: 0.2820586117299843\n",
      "Epoch 4, train loss: 0.17568438879501225\n",
      "Epoch 5, train loss: 0.1353227472597513\n",
      "Epoch 6, train loss: 0.12383510290909372\n",
      "Epoch 7, train loss: 0.1170544926208715\n",
      "Epoch 8, train loss: 0.10043174195490169\n",
      "Epoch 9, train loss: 0.08791557144845556\n",
      "Epoch 10, train loss: 0.08990672212513788\n",
      "Epoch 11, train loss: 0.07711570228741535\n",
      "Epoch 12, train loss: 0.07357874988259501\n",
      "Epoch 13, train loss: 0.0663940989725455\n",
      "Epoch 14, train loss: 0.06042445482556843\n",
      "Epoch 15, train loss: 0.057545808112434815\n",
      "Epoch 16, train loss: 0.057701378731209056\n",
      "Epoch 17, train loss: 0.04125715897534265\n",
      "Epoch 18, train loss: 0.03993344711974699\n",
      "Epoch 19, train loss: 0.03731393122741551\n",
      "Epoch 20, train loss: 0.04178936425290194\n",
      "Epoch 21, train loss: 0.029520725078163862\n",
      "Epoch 22, train loss: 0.030725766763422323\n",
      "Epoch 23, train loss: 0.03073851256200252\n",
      "Epoch 24, train loss: 0.027065041385807696\n",
      "Epoch 25, train loss: 0.028531415961698676\n",
      "Epoch 26, train loss: 0.028396818987360444\n",
      "Epoch 27, train loss: 0.03220008195524788\n",
      "Epoch 28, train loss: 0.03603275676726406\n",
      "Epoch 29, train loss: 0.029414492034513264\n",
      "Epoch 30, train loss: 0.03951287304190749\n",
      "Epoch 31, train loss: 0.02892754070719434\n",
      "Epoch 32, train loss: 0.02802411971520746\n",
      "Epoch 33, train loss: 0.030156534204563528\n",
      "Epoch 34, train loss: 0.030321307528404413\n",
      "Epoch 35, train loss: 0.03480302097857788\n",
      "Epoch 36, train loss: 0.035179878317895055\n",
      "Epoch 37, train loss: 0.03608181548302587\n",
      "Epoch 38, train loss: 0.02863779110605993\n",
      "Epoch 39, train loss: 0.02641647175662265\n",
      "Epoch 40, train loss: 0.025762761740556188\n",
      "Epoch 41, train loss: 0.02573411182322325\n",
      "Epoch 42, train loss: 0.032699763415558275\n",
      "Epoch 43, train loss: 0.026208564852070557\n",
      "Epoch 44, train loss: 0.03292848733673496\n",
      "Epoch 45, train loss: 0.032388239582812235\n",
      "Epoch 46, train loss: 0.03008404019998838\n",
      "Epoch 47, train loss: 0.028079133828473476\n",
      "Epoch 48, train loss: 0.027548169602337094\n",
      "Epoch 49, train loss: 0.034499014752443956\n",
      "Epoch 50, train loss: 0.025201435477657744\n",
      "Epoch 51, train loss: 0.02447964824496765\n",
      "Epoch 52, train loss: 0.030016418822375143\n",
      "Epoch 53, train loss: 0.026546563453468678\n",
      "Epoch 54, train loss: 0.034892389762082594\n",
      "Epoch 55, train loss: 0.02677032346389144\n",
      "Epoch 56, train loss: 0.03931044452102236\n",
      "Epoch 57, train loss: 0.02841112448098807\n",
      "Epoch 58, train loss: 0.02506176436980154\n",
      "Epoch 59, train loss: 0.024645613446881615\n",
      "Epoch 60, train loss: 0.02403228376576865\n",
      "Epoch 61, train loss: 0.02702488815105644\n",
      "Epoch 62, train loss: 0.02826724662054126\n",
      "Epoch 63, train loss: 0.03195044479755987\n",
      "Epoch 64, train loss: 0.029807959249624292\n",
      "Epoch 65, train loss: 0.0283593030654384\n",
      "Epoch 66, train loss: 0.02654734337628659\n",
      "Epoch 67, train loss: 0.027891751110494755\n",
      "Epoch 68, train loss: 0.026223201496950857\n",
      "Epoch 69, train loss: 0.022799638501537486\n",
      "Epoch 70, train loss: 0.023352025598985224\n",
      "Epoch 71, train loss: 0.024370588647228884\n",
      "Epoch 72, train loss: 0.031177830533266303\n",
      "Epoch 73, train loss: 0.036245889624242696\n",
      "Epoch 74, train loss: 0.02521210151467014\n",
      "Epoch 75, train loss: 0.029758182196309574\n",
      "Epoch 76, train loss: 0.024343261999179053\n",
      "Epoch 77, train loss: 0.025595551840200948\n",
      "Epoch 78, train loss: 0.02680888986095886\n",
      "Epoch 79, train loss: 0.02567313000107191\n",
      "Epoch 80, train loss: 0.026764120859514816\n",
      "Epoch 81, train loss: 0.028673988891466\n",
      "Epoch 82, train loss: 0.02688455222861957\n",
      "Epoch 83, train loss: 0.029254668515604376\n",
      "Epoch 84, train loss: 0.025855754644481803\n",
      "Epoch 85, train loss: 0.03196749920433843\n",
      "Epoch 86, train loss: 0.029223090414883485\n",
      "Epoch 87, train loss: 0.028324402970841538\n",
      "Epoch 88, train loss: 0.024611841636538578\n",
      "Epoch 89, train loss: 0.02796389382751148\n",
      "Epoch 90, train loss: 0.025956296557946252\n",
      "Epoch 91, train loss: 0.025073698171937383\n",
      "Epoch 92, train loss: 0.028324728396332093\n",
      "Epoch 93, train loss: 0.02692354192115575\n",
      "Epoch 94, train loss: 0.03012827431372436\n",
      "Epoch 95, train loss: 0.030884618735639663\n",
      "Epoch 96, train loss: 0.02497932879082931\n",
      "Epoch 97, train loss: 0.02873465841966165\n",
      "Epoch 98, train loss: 0.030157107392203484\n",
      "Epoch 99, train loss: 0.025414326791702593\n"
     ]
    }
   ],
   "source": [
    "model, losses_train = train_model(model, dataloader_wind_total, None, criterion, optimizer, num_epochs=N_EPOCHS, apply_gradient_clipping=True, grad_clip_param=grad_clip_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'total_wind_1h_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "plt.plot(losses_train, label='RMSE')\n",
    "#plt.plot(losses_val, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_wind_1h_total.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26279, 25, 11) (26279, 1)\n"
     ]
    }
   ],
   "source": [
    "total_solar = np.concatenate((solar_data, solar_data_val), axis=0)\n",
    "total_solar_X, total_solar_y = move_sliding_window(total_solar, WINDOW_SIZE, range(11), 0)\n",
    "total_solar_dataset = SolarDataset(total_solar_X, total_solar_y)\n",
    "dataloader_solar_total = DataLoader(total_solar_dataset, batch_size=32, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Béla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#Best parameters: {'batch_size': 64, 'iterator_train__shuffle': False, 'max_epochs': 80, 'module__drop_prob': 0.5, 'module__hidden_dim': 64, 'module__n_layers': 1, 'optimizer__lr': 0.001, 'optimizer__weight_decay': 0.001}\n",
    "BAT_SIZE = 64\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 1\n",
    "lr = 0.001\n",
    "weight_decay = 0.001\n",
    "N_EPOCHS = 100\n",
    "DROP_PROB = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "grad_clip_param = 2\n",
    "\n",
    "solar_1h_model = GRUNet(input_dim=INPUT_SIZE, hidden_dim=HIDDEN_SIZE, output_dim=OUTPUT_SIZE, n_layers=NUM_LAYERS, drop_prob=DROP_PROB).to(device)\n",
    "optimizer = torch.optim.Adam(solar_1h_model.parameters(), lr=lr, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.5343758915794897\n",
      "Epoch 1, train loss: 0.5343758915794897\n",
      "Epoch 2, train loss: 0.5343758915794897\n",
      "Epoch 3, train loss: 0.5343758915794897\n",
      "Epoch 4, train loss: 0.5343758915794897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m solar_1h_model, losses_train_solar_1h \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolar_1h_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_solar_total\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_gradient_clipping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_clip_param\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 24\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, grad_clip_param, apply_gradient_clipping)\u001b[0m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(criterion(output, target\u001b[38;5;241m.\u001b[39mfloat()) \u001b[38;5;241m+\u001b[39m eps)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# gradient clipping\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_gradient_clipping:\n\u001b[0;32m     26\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), grad_clip_param)\n",
      "File \u001b[1;32mc:\\Users\\Béla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Béla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "solar_1h_model, losses_train_solar_1h = train_model(solar_1h_model, dataloader_solar_total, None, criterion, optimizer, num_epochs=N_EPOCHS, apply_gradient_clipping=True, grad_clip_param=grad_clip_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(solar_1h_model.state_dict(), 'total_solar_1h_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_train_solar_1h, label='RMSE')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_solar_1h_total.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sliding_window_2(data, window_size, inputs_cols_indices, label_col_index, forecast_horizon=24):\n",
    "    \"\"\"\n",
    "    data: numpy array including data\n",
    "    window_size: size of window\n",
    "    inputs_cols_indices: col indices to include\n",
    "    label_col_index: index of the label column in data\n",
    "    forecast_horizon: number of time steps ahead to predict\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the number of instances based on the available data minus the window size and forecast horizon\n",
    "    num_instances = len(data) - window_size - forecast_horizon + 1\n",
    "\n",
    "    # (# instances created by movement, seq_len (timestamps), # features (input_len))\n",
    "    inputs = np.zeros((num_instances, window_size, len(inputs_cols_indices)))\n",
    "    labels = np.zeros(num_instances)\n",
    "\n",
    "    for i in range(num_instances):\n",
    "        inputs[i] = data[i:i + window_size, inputs_cols_indices]\n",
    "        labels[i] = data[i + window_size + forecast_horizon - 1, label_col_index]  # Label is forecast_horizon steps ahead\n",
    "    inputs = inputs.reshape(-1, window_size, len(inputs_cols_indices))\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    print(inputs.shape, labels.shape)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_solar_24h_X, total_solar_24h_y = move_sliding_window_2(total_solar, WINDOW_SIZE, range(11), 0, forecast_horizon=24)\n",
    "total_solar_24h_dataset = SolarDataset(total_solar_24h_X, total_solar_24h_y)\n",
    "dataloader_solar_total_24h = DataLoader(total_solar_24h_dataset, batch_size=32, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#est parameters: {'batch_size': 64, 'iterator_train__shuffle': False, 'max_epochs': 80, 'module__drop_prob': 0.5, 'module__hidden_dim': 16, 'module__n_layers': 1, 'optimizer__lr': 0.001, 'optimizer__weight_decay': 0.001}\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "HIDDEN_SIZE = 16\n",
    "NUM_LAYERS = 1\n",
    "lr = 0.001\n",
    "weight_decay = 0.001\n",
    "DROP_PROB = 0.5\n",
    "grad_clip_param = 2\n",
    "\n",
    "model_solar_24h = GRUNet(input_dim=INPUT_SIZE, hidden_dim=HIDDEN_SIZE, output_dim=OUTPUT_SIZE, n_layers=NUM_LAYERS, drop_prob=DROP_PROB).to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
